configfile: 'config.yaml'

rule reformat_ae_l1_data:
    input:
        data = config['dataset'],
        teacher_json = config['json'],
        teacher_h5 = config['h5']
    output:
        train_loss = 'output/l1_ae_train_loss.h5',
        test_loss = 'output/l1_ae_test_loss.h5',
        signal_loss = 'output/l1_ae_signal_loss.h5'
    shell:
        'mkdir -p output;'
        'python reformat_ae_l1_data.py --data-file {input.data} \
                                       --teacher-input-json {input.teacher_json} \
                                       --teacher-input-h5 {input.teacher_h5} \
                                       --output-train-loss {output.train_loss} \
                                       --output-test-loss {output.test_loss} \
                                       --output-signal-loss {output.signal_loss}'

rule kd_ae_l1_train:
    input:
        train = rules.reformat_ae_l1_data.output.train_loss,
        test = rules.reformat_ae_l1_data.output.test_loss,
        signal = rules.reformat_ae_l1_data.output.signal_loss,
    output:
        h5 = 'output/student_model.h5',
        json = 'output/student_model.json',
        result = 'output/student_result.h5'
    params:
        data_name = 'data',
        loss_name = 'teacher_loss',
        distillation_loss = 'mae',
        n_features = 3,
        plots = 'plots/ae_l1/'
    shell:
        'mkdir -p {params.plots};'
        'python knowledge_distillation.py --input-train-file {input.train} \
                                          --input-test-file {input.test} \
                                          --input-signal-file {input.signal} \
                                          --data-name {params.data_name} \
                                          --n-features {params.n_features} \
                                          --teacher-loss_name {params.loss_name} \
                                          --output-model-h5 {output.h5} \
                                          --output-model-json {output.json} \
                                          --node-size 32 \
                                          --batch-size 1024 \
                                          --n-epochs 100 \
                                          --distillation-loss {params.distillation_loss}\
                                          --output-result {output.result} \
                                          --output-dir {params.plots} '

rule kd_ae_l1_plot:
    input:
        student = rules.kd_ae_l1_train.output.result,
        teacher = rules.reformat_ae_l1_data.output.test_loss,
        signal = rules.reformat_ae_l1_data.output.signal_loss
    params:
        loss_name = 'teacher_loss',
        plots = 'plots/ae_l1/'
    shell:
        'mkdir -p {params.plots};'
        'python plot_results.py --student {input.student} \
                                --teacher {input.teacher} \
                                --teacher-loss-name {params.loss_name} \
                                --output-dir {params.plots} \
                                --signal {input.signal}'

rule kd_graph_train:
    input:
        train = config['train'],
        test = config['test'],
        signal = config['signal']
    output:
        h5 = 'output/graph_student_model.h5',
        json = 'output/graph_student_model.json',
        result = 'output/graph_student_result.h5'
    params:
        data_name = 'InputParticlesOriginal',
        loss_name = 'loss_pid', # loss_all_reco_chamfer
        distillation_loss = 'mse',
        n_features = 3,
        plots = 'plots/graph/'
    shell:
        'mkdir -p {params.plots};'
        'python knowledge_distillation.py --input-train-file {input.train} \
                                          --input-test-file {input.test} \
                                          --input-signal-file {input.signal} \
                                          --data-name {params.data_name} \
                                          --n-features {params.n_features} \
                                          --teacher-loss_name {params.loss_name} \
                                          --output-model-h5 {output.h5} \
                                          --output-model-json {output.json} \
                                          --batch-size 1024 \
                                          --n-epochs 100 \
                                          --distillation-loss {params.distillation_loss}\
                                          --output-result {output.result} \
                                          --output-dir {params.plots} '

rule kd_graph_plot:
    input:
        student = rules.kd_graph_train.output.result,
        signal = config['signal'],
        teacher = config['test']
    params:
        loss_name = 'loss_pid',
        plots = 'plots/graph/'
    shell:
        'mkdir -p {params.plots};'
        'python plot_results.py --student {input.student} \
                                --teacher {input.teacher} \
                                --teacher-loss-name {params.loss_name} \
                                --output-dir {params.plots} \
                                --signal {input.signal}'

